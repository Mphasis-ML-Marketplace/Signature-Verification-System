{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signature Verification System\n",
    "\n",
    "This solution demonstrates an end-to-end signature verification system. The solution eliminates the need to manually verify the signature, reducing the occurrence of human error and fraud during the authentication process. It extracts the signature from the scanned input image and validate it with the original signature stored in the database. It then produces a confidence score based on Structural Similarity Index(SSIM) to indicate the signatureâ€™s level of authenticity. A SSIM score close to 1 indicates authentic pair of signatures.\n",
    "\n",
    "### Prerequisite\n",
    "\n",
    "To run this algorithm you need to have access to the following AWS Services:\n",
    "- Access to AWS SageMaker and the model package.\n",
    "- An S3 bucket to specify input/output.\n",
    "- Role for AWS SageMaker to access input/output from S3.\n",
    "\n",
    "This sample notebook shows you how to deploy Signature Verification System using Amazon SageMaker.\n",
    "\n",
    "> **Note**: This is a reference notebook and it cannot run unless you make changes suggested in the notebook.\n",
    "\n",
    "#### Pre-requisites:\n",
    "1. **Note**: This notebook contains elements which render correctly in Jupyter interface. Open this notebook from an Amazon SageMaker Notebook Instance or Amazon SageMaker Studio.\n",
    "1. Ensure that IAM role used has **AmazonSageMakerFullAccess**\n",
    "1. To deploy this ML model successfully, ensure that:\n",
    "    1. Either your IAM role has these three permissions and you have authority to make AWS Marketplace subscriptions in the AWS account used: \n",
    "        1. **aws-marketplace:ViewSubscriptions**\n",
    "        1. **aws-marketplace:Unsubscribe**\n",
    "        1. **aws-marketplace:Subscribe**  \n",
    "    2. or your AWS account has a subscription to Signature Verification System. If so, skip step: [Subscribe to the model package](#1.-Subscribe-to-the-model-package)\n",
    "\n",
    "#### Contents:\n",
    "1. [Subscribe to the model package](#1.-Subscribe-to-the-model-package)\n",
    "2. [Create an endpoint and perform real-time inference](#2.-Create-an-endpoint-and-perform-real-time-inference)\n",
    "   1. [Create an endpoint](#A.-Create-an-endpoint)\n",
    "   2. [Create input payload](#B.-Create-input-payload)\n",
    "   3. [Perform real-time inference](#C.-Perform-real-time-inference)\n",
    "   4. [Output Result](#D.-Output-Result)\n",
    "   5. [Delete the endpoint](#E.-Delete-the-endpoint)\n",
    "3. [Perform batch inference](#3.-Perform-batch-inference) \n",
    "4. [Clean-up](#4.-Clean-up)\n",
    "    1. [Delete the model](#A.-Delete-the-model)\n",
    "    2. [Unsubscribe to the listing (optional)](#B.-Unsubscribe-to-the-listing-(optional))\n",
    "    \n",
    "\n",
    "#### Usage instructions\n",
    "You can run this notebook one cell at a time (By using Shift+Enter for running a cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Subscribe to the model package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To subscribe to the model package:\n",
    "1. Open the model package listing page Signature Verification System.\n",
    "1. On the AWS Marketplace listing, click on the **Continue to subscribe** button.\n",
    "1. On the **Subscribe to this software** page, review and click on **\"Accept Offer\"** if you and your organization agrees with EULA, pricing, and support terms. \n",
    "1. Once you click on **Continue to configuration button** and then choose a **region**, you will see a **Product Arn** displayed. This is the model package ARN that you need to specify while creating a deployable model using Boto3. Copy the ARN corresponding to your region and specify the same in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package_arn='arn:aws:sagemaker:us-east-2:786796469737:model-package/signature-verification-copy-02-03'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import boto3\n",
    "from zipfile import ZipFile\n",
    "import uuid\n",
    "from sagemaker import ModelPackage\n",
    "import sagemaker as sage\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker import ModelPackage\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "\n",
    "sagemaker_session = sage.Session()\n",
    "\n",
    "bucket=sagemaker_session.default_bucket()\n",
    "bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create an endpoint and perform real-time inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to understand how real-time inference with Amazon SageMaker works, see [Documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-hosting.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='signature-verification-1'\n",
    "\n",
    "content_type='application/zip'\n",
    "\n",
    "real_time_inference_instance_type='ml.m5.large'\n",
    "batch_transform_inference_instance_type='ml.m5.large'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Create an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_wrapper(endpoint, session):\n",
    "    return sage.predictor.RealTimePredictor(endpoint, session,content_type)\n",
    "\n",
    "#create a deployable model from the model package.\n",
    "\n",
    "model = ModelPackage(role=role,\n",
    "                    model_package_arn=model_package_arn,\n",
    "                    sagemaker_session=sagemaker_session,\n",
    "                    predictor_cls=predict_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = model.deploy(1, real_time_inference_instance_type, endpoint_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once endpoint has been created, you would be able to perform real-time inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Create input payload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instructions\n",
    "\n",
    "Input.zip should contain two folders:\n",
    "\n",
    "    1) document: This folder will have the image documents from where signatures will be extracted for verification.\n",
    "\n",
    "    2) signature_database: This folder will contain the signatures which will be used to verify the extracted signatures.\n",
    "\n",
    "Name of the image documents in the document folder and signatures in the signature_database folder must be same. For better understanding, please check Input.zip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'Input.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Perform real-time inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "    \"ContentType\": \"application/json\",\r\n",
      "    \"InvokedProductionVariant\": \"AllTraffic\"\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!aws sagemaker-runtime invoke-endpoint --endpoint-name $model_name --body fileb://$file_name --content-type 'application/zip' --region us-east-2 output.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D. Output Result\n",
    "\n",
    "- The output file (in json format) contains the following files:\n",
    "\n",
    "    1. 'output.json': dictionary containing image document name as key and similarity score as values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "file_path = os.getcwd()\n",
    "file_name = 'output.json'\n",
    "\n",
    "#file_object = open(file_name,'rb')\n",
    "with open(file_name,'r') as f:\n",
    "    json_array=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accaptance_form.jpg': {'similarity_score': 0.83},\n",
       " 'proposition.jpg': {'similarity_score': 0.57}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E. Delete the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have successfully performed a real-time inference, you do not need the endpoint any more. You can terminate the endpoint to avoid being charged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor=sage.predictor.Predictor(model_name, sagemaker_session,content_type)\n",
    "predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Perform batch inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will perform batch inference using multiple input payloads together. If you are not familiar with batch transform, and want to learn more, see these links:\n",
    "1. [How it works](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-batch-transform.html)\n",
    "2. [How to run a batch transform job](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-batch.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload the batch-transform job input files to S3\n",
    "transform_input_folder = \"data/input/batch\"\n",
    "transform_input = sagemaker_session.upload_data(transform_input_folder, key_prefix=model_name) \n",
    "print(\"Transform input uploaded to \" + transform_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................\u001b[34m * Serving Flask app 'serve' (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\u001b[0m\n",
      "\u001b[34m#033[31m#033[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.#033[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:8080\n",
      " * Running on http://169.254.255.131:8080\u001b[0m\n",
      "\u001b[34m#033[33mPress CTRL+C to quit#033[0m\u001b[0m\n",
      "\u001b[35m * Serving Flask app 'serve' (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\u001b[0m\n",
      "\u001b[35m#033[31m#033[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.#033[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:8080\n",
      " * Running on http://169.254.255.131:8080\u001b[0m\n",
      "\u001b[35m#033[33mPress CTRL+C to quit#033[0m\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [06/Feb/2023 05:24:43] \"GET /ping HTTP/1.1\" 200 -\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [06/Feb/2023 05:24:43] \"GET /ping HTTP/1.1\" 200 -\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [06/Feb/2023 05:24:43] \"#033[33mGET /execution-parameters HTTP/1.1#033[0m\" 404 -\u001b[0m\n",
      "\u001b[34mprevious Input.zip didn't exist\u001b[0m\n",
      "\u001b[34mExtracting all the files now...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [06/Feb/2023 05:24:43] \"#033[33mGET /execution-parameters HTTP/1.1#033[0m\" 404 -\u001b[0m\n",
      "\u001b[35mprevious Input.zip didn't exist\u001b[0m\n",
      "\u001b[35mExtracting all the files now...\u001b[0m\n",
      "\u001b[34m/bin/sh: 1: git: not found\u001b[0m\n",
      "\u001b[34mYOLOv5 ðŸš€ 2023-1-23 Python-3.8.10 torch-1.7.1 CPU\u001b[0m\n",
      "\u001b[34mFusing layers... \u001b[0m\n",
      "\u001b[35m/bin/sh: 1: git: not found\u001b[0m\n",
      "\u001b[35mYOLOv5 ðŸš€ 2023-1-23 Python-3.8.10 torch-1.7.1 CPU\u001b[0m\n",
      "\u001b[35mFusing layers... \u001b[0m\n",
      "\u001b[32m2023-02-06T05:24:43.688:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34mSimilarity score between extracted signature and stored signature for accaptance_form.jpg is 0.83\u001b[0m\n",
      "\u001b[34mSimilarity score between extracted signature and stored signature for proposition.jpg is 0.57\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [06/Feb/2023 05:24:50] \"POST /invocations HTTP/1.1\" 200 -\u001b[0m\n",
      "\u001b[35mSimilarity score between extracted signature and stored signature for accaptance_form.jpg is 0.83\u001b[0m\n",
      "\u001b[35mSimilarity score between extracted signature and stored signature for proposition.jpg is 0.57\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [06/Feb/2023 05:24:50] \"POST /invocations HTTP/1.1\" 200 -\u001b[0m\n",
      "\n",
      "\u001b[34m * Serving Flask app 'serve' (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\u001b[0m\n",
      "\u001b[34m#033[31m#033[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.#033[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:8080\n",
      " * Running on http://169.254.255.131:8080\u001b[0m\n",
      "\u001b[34m#033[33mPress CTRL+C to quit#033[0m\u001b[0m\n",
      "\u001b[35m * Serving Flask app 'serve' (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\u001b[0m\n",
      "\u001b[35m#033[31m#033[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.#033[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:8080\n",
      " * Running on http://169.254.255.131:8080\u001b[0m\n",
      "\u001b[35m#033[33mPress CTRL+C to quit#033[0m\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [06/Feb/2023 05:24:43] \"GET /ping HTTP/1.1\" 200 -\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [06/Feb/2023 05:24:43] \"GET /ping HTTP/1.1\" 200 -\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [06/Feb/2023 05:24:43] \"#033[33mGET /execution-parameters HTTP/1.1#033[0m\" 404 -\u001b[0m\n",
      "\u001b[34mprevious Input.zip didn't exist\u001b[0m\n",
      "\u001b[34mExtracting all the files now...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [06/Feb/2023 05:24:43] \"#033[33mGET /execution-parameters HTTP/1.1#033[0m\" 404 -\u001b[0m\n",
      "\u001b[35mprevious Input.zip didn't exist\u001b[0m\n",
      "\u001b[35mExtracting all the files now...\u001b[0m\n",
      "\u001b[34m/bin/sh: 1: git: not found\u001b[0m\n",
      "\u001b[34mYOLOv5 ðŸš€ 2023-1-23 Python-3.8.10 torch-1.7.1 CPU\u001b[0m\n",
      "\u001b[34mFusing layers... \u001b[0m\n",
      "\u001b[35m/bin/sh: 1: git: not found\u001b[0m\n",
      "\u001b[35mYOLOv5 ðŸš€ 2023-1-23 Python-3.8.10 torch-1.7.1 CPU\u001b[0m\n",
      "\u001b[35mFusing layers... \u001b[0m\n",
      "\u001b[32m2023-02-06T05:24:43.688:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34mimage 1/2 /opt/program/output/accaptance_form.jpg: 640x544 1 DLSignature, 2270.7ms\u001b[0m\n",
      "\u001b[35mimage 1/2 /opt/program/output/accaptance_form.jpg: 640x544 1 DLSignature, 2270.7ms\u001b[0m\n",
      "\u001b[34mimage 2/2 /opt/program/output/proposition.jpg: 640x480 1 DLSignature, 1873.0ms\u001b[0m\n",
      "\u001b[34mSpeed: 1.7ms pre-process, 2071.9ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\u001b[0m\n",
      "\u001b[34mSimilarity score between extracted signature and stored signature for accaptance_form.jpg is 0.83\u001b[0m\n",
      "\u001b[34mSimilarity score between extracted signature and stored signature for proposition.jpg is 0.57\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [06/Feb/2023 05:24:50] \"POST /invocations HTTP/1.1\" 200 -\u001b[0m\n",
      "\u001b[35mimage 2/2 /opt/program/output/proposition.jpg: 640x480 1 DLSignature, 1873.0ms\u001b[0m\n",
      "\u001b[35mSpeed: 1.7ms pre-process, 2071.9ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\u001b[0m\n",
      "\u001b[35mSimilarity score between extracted signature and stored signature for accaptance_form.jpg is 0.83\u001b[0m\n",
      "\u001b[35mSimilarity score between extracted signature and stored signature for proposition.jpg is 0.57\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [06/Feb/2023 05:24:50] \"POST /invocations HTTP/1.1\" 200 -\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Run the batch-transform job\n",
    "transformer = model.transformer(1, batch_transform_inference_instance_type)\n",
    "transformer.transform(transform_input, content_type=content_type)\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output is available on following path\n",
    "transformer.output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_conn = boto3.client(\"s3\")\n",
    "bucket_name=\"sagemaker-us-east-2-786796469737\"\n",
    "with open('output.json', 'wb') as f:\n",
    "    s3_conn.download_fileobj(bucket_name, os.path.basename(transformer.output_path)+'/Input.zip.out', f)\n",
    "    print(\"Output file loaded from bucket\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "file_path = os.getcwd()\n",
    "file_name = 'output.json'\n",
    "\n",
    "#file_object = open(file_name,'rb')\n",
    "with open(file_name,'r') as f:\n",
    "    json_array=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accaptance_form.jpg': {'similarity_score': 0.83},\n",
       " 'proposition.jpg': {'similarity_score': 0.57}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Clean-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Delete the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.delete_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Unsubscribe to the listing (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to unsubscribe to the model package, follow these steps. Before you cancel the subscription, ensure that you do not have any [deployable model](https://console.aws.amazon.com/sagemaker/home#/models) created from the model package or using the algorithm. Note - You can find this information by looking at the container name associated with the model. \n",
    "\n",
    "**Steps to unsubscribe to product from AWS Marketplace**:\n",
    "1. Navigate to __Machine Learning__ tab on [__Your Software subscriptions page__](https://aws.amazon.com/marketplace/ai/library?productType=ml&ref_=mlmp_gitdemo_indust)\n",
    "2. Locate the listing that you want to cancel the subscription for, and then choose __Cancel Subscription__  to cancel the subscription."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
